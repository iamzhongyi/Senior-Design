import speech_recognition as sr
import threading
from threading import Thread, current_thread
import time
from multiprocessing import Process, Queue, Manager 
import datetime
import sklearn.datasets
from sklearn.datasets import load_files
import sklearn.metrics
import sklearn.svm
import sklearn.naive_bayes
import numpy as np
from sklearn.naive_bayes import MultinomialNB
import sklearn.neighbors
from sklearn import svm
import sys, os, glob
from pprint import pprint

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer

def Vote(text):
	VoteB,VoteD = HardClassify(text)
	VoteML = MLClassify(text)
	Advanced = 0 
	if (Advanced):
		return VoteML
	else:
		if VoteD == VoteB:
			return VoteB
		else:
			return VoteML



def HardClassify(text):
        # A simple example of the conversation
        # This information will be pass by the speech recognize API( text[i] = marker + r.recognize_google(audio[i]) )
        # Note: recognize result from Google Speech API does not include any punctuation
        """
            text = []
            text.append("")
            text[0] = "[D] Hello Mr Potter could you please talk something about yourself"
            text.append("")
            text[1] = "[P] Hello Dr Ingham I am Harry Potter a student 21 years old 170 centimeters height 65 kilograms weight Currently catched a cold"
            text.append("")
            text[2] = "[D] What are the symptoms that trouble you Specifically"
            text.append("")
            text[3] = "[P] I have been coughing for half a week and have been running a fever"
            text.append("")
            text[4] = "[D] I see and do you allergy to any kind of medicine"
            text.append("")
            text[5] = "[P] Might be Penicillins my former doctor told me don't use that"
            
            """
        # A sample keyword database
        # The actual database should be generated by SQL or a Spider
        keywordindex = ["Name", "Information", "History", "Billing", "Symptoms", "Allergy", "Family", "Organ","Be","Medicine"]
        keywordcategory = []
        keywordcategory.append("")
        #Name
        keywordcategory[0] = {"am","I'm"}
        keywordcategory.append("")
        #Information
        keywordcategory[1] = {"centimeter","centimeters","meter","meters","inch","inchs","worker", "student" , "teacher", "professor"}
        keywordcategory.append("")
        #Time
        keywordcategory[2] = {"days","day","weeks","week","year","years","month","months","recent","recently","current","time"}
        keywordcategory.append("")
        #Billing
        keywordcategory[3] = {"worker", "student" , "teacher", "professor"}
        keywordcategory.append("")
        #Symptoms
        keywordcategory[4] = {"cough", "coughed", "coughing", "fever", "ache", "itch","headache","temperature","worn"}
        keywordcategory.append("")
        #Allergy
        keywordcategory[5] = {"penicillins" , "aspirins"}
        keywordcategory.append("")
        #Family
        keywordcategory[6] = {"father" , "mother", "dad", "mom", "grandpa", "grandma", "son", "daugher", "sister", "brother", "cousin", "wife", "husband"}
        keywordcategory.append("")
        #Organ
        keywordcategory[7] = {"head","eye","eyes","nose","ear","ears","mouth","leg","legs","heart","arm","arms","lung","lungs"}
        keywordcategory.append("")
        #Be
        keywordcategory[8] = {"is","am","are","was","were","be"}
        keywordcategory.append("")

        #Medicine

        keywordcategory[9] = {"antibiotic"}

        # Splitting the text, and make the text not sensitive to the upper/lower cases
        textsplit = []
        textsplit = text.split()
            #for i in range (0, len(text)):
            #text[i] = text[i].lower()
            #textsplit.append(text[i].split())
        #print (textsplit[i])
        
        # Analyzing the text (Keyword Comparing)
        record = []
        for k in range (0, len(keywordcategory)):
            record.append([])


        cateLookUp = {"Name":0, "Information": 1, "Time":2 , "Billing": 3, \
                    "Symptoms": 4, "Allergy": 5, "Family":6, "Organ":7,"Be":8,"Medicine":9}
        tag = []
        Detected = [0,0,0,0,0,0,0,0,0,0]
        for o in range(0,len(textsplit)):
            tag.append(0)

        for j in range (0, len(textsplit)):
            for k in range (0, len(keywordcategory)):
                if textsplit[j] in keywordcategory[k] :
                            Detected[k] = 1
                            tag[j] = k
                            record[k].append(textsplit[j])
                            if k == 4 :
                                print("symptom detected")
                                #record[k].append(textsplit[j])
                                if k == 0 :
                                    print("name detected")
                                    #record[k].append(textsplit[j+1])
                            if k == 1 or k == 2:
                                print("time detect")
                                #record[k].append(textsplit[j-1])

        #Decision Tree Network

        # Symptom layer, detect symptoms
        if (len(record[cateLookUp['Symptoms']]) > 0):
            # Family Layer, detect family members
            if (len(record[cateLookUp['Family']]) > 0):
                # Report Family history
                VoteD = 'Family_History'
                print('Report Family history')
                #print(record[cateLookUp['Family']][0] + " : " + record[cateLookUp['Symptoms']][0])
            # Time Layer, detect Time information
            elif (len(record[cateLookUp['Time']]) > 0):
                # Long period
                if ("year" in record[cateLookUp['Time']] \
                    or "years" in record[cateLookUp['Time']]):
                    # Report Problem list
                    VoteD = 'Problem_List'
                    print('Report Problem list')
                    #print(record[cateLookUp['Symptoms']])

                else: 
                    # Report History of present illness
                    VoteD = 'HPI'
                    print('Report HPI')
                    #print(record[cateLookUp['Symptoms']][0] + " for " + record[cateLookUp['Time']][0])
            else: 
                # Report Problem list
                VoteD = 'Problem_List'
                print('Report Problem list')
                #print(record[cateLookUp['Symptoms']])


        # No symptom found, detect organ
        elif (len(record[cateLookUp['Organ']]) > 0): 
            # Report phycial Exam
            VoteD = 'Physical_Exam'
            print('Report physical Exam')
            #print(text)

        # No organ found, check for special set
        else: 
            VoteD = 'Special_Sets'
            print('Enter special sets')
                        #End the Conversation
            if (("all" in textsplit) and ("bye" in textsplit)):
                    print("Conversation End")
                    exit(0)

            if (("questions" in textsplit) and ("yes" in textsplit) and ("no" in textsplit)):
                    negatives_flag = 1








        #Naive Fixed Bayes


        #Currently four kinds of outputs enabled.



        cateLookUp = {"Name":0, "Information": 1, "Time":2 , "Billing": 3, \
                    "Symptoms": 4, "Allergy": 5, "Family":6, "Organ":7,"Be":8,"Medicine":9}
        ResultLookUp = ["Family_History", "Problem_List","Physical_Exam","HPI"]
        ResultProbB = [1.,1.,1.,1.]
        BayesTable = [[0.4,0.2,0.5,0.5,1.0,0.5,1.5,0.5,0.5,0.5], \
                      [0.7,0.2,0.5,0.5,1.0,0.5,0.1,0.5,0.5,0.2], \
                      [0.2,0.2,0.2,0.2,0.2,0.1,0.1,2.0,0.7,0.1], \
                      [0.5,0.2,1.0,0.5,1.2,0.2,0.2,0.7,0.5,0.4]]




        for i in range(0,len(ResultProbB)) :
            for j in range(0,len(BayesTable[i])) :
                if Detected[j] == 1:
                    ResultProbB[i] = ResultProbB[i] * BayesTable[i][j]
                else:
                    ResultProbB[i] = ResultProbB[i] * 0.5
        ##print("The result of Bayes Table:")
        largest = 0
        largestindex = 0
        for i in range(0,len(ResultProbB)) :
         ##   print(ResultProbB[i])
            if ResultProbB[i] > largest:
                largest = ResultProbB[i]
                largestindex = i
        print(ResultLookUp[largestindex])

        VoteB = ResultLookUp[largestindex]
        print("vote result")
        print(VoteB,VoteD)

        if VoteB == VoteD :
            print("Quite sure about the classify result, generating training data")
            currenttime = datetime.datetime.now()
            currenttime = ''.join(["Date:",str(currenttime)])
            filename = ''.join([currenttime,".txt"])
            fullfilename = ''.join([VoteB,"/",filename])
            trainingfile = open(fullfilename,"w")
            trainingfile.write(text)
            trainingfile.close



            #Output the extracting results
        #for i in range (0, len(keywordcategory)):
            #print (keywordindex[i])
            #print (record[i])
        return VoteB,VoteD




def MLClassify(text):

	'''
	test_path = './testing'
	test_files = sklearn.datasets.load_files(test_path, encoding = 'latin1', load_content=True)
	#
	# print(test_files)
	print("test_files")
	print(test_files.data)
	X_test_counts = count_vect.transform(test_files.data)
	print("X_test_counts")
	print(X_test_counts.toarray())
	X_test_tfidf = tfidf_transformer.transform(X_test_counts)
	print("X_test_tfidf")
	print(X_test_tfidf.toarray())
	# print(X_test_counts.shape)
	predicted = svm.predict_proba(X_test_counts)
	#
	print("svm.predict")
	print(svm.predict(X_test_counts))
	print("predicted")
	print(predicted)
	'''

	#count_vect = CountVectorizer()
	#print("train",files)
	X_test_countst = count_vect.transform([text])

	X_test_tfidft = tfidf_transformer.transform(X_test_countst)
	predict_result = svmi.predict_proba(X_test_tfidft)
	print("test = " , svmi.predict_proba(X_test_tfidft))
	print(predict_result.shape)
	#print(predict_result[0][1])
	#print(predict_result.shape[1])
	print(svmi.predict(X_test_countst))
	#print(X_test_countst.toarray())
	MLcategory = ["Allergies","Assessment","Family_History","HPI","Medical_History","Medications","Patient_Instructions","Physical_Exam","Plan","Review_of_Systems"]
	return MLcategory[svmi.predict(X_test_countst)[0]]

	#for i in range(predict_result.shape[1]):
def Record(person):
	#target the microphone by id or by name
	if (person == "doctor"):
		#mic_name = "USB PnP Sound Device" 
		device_id = 4
	else:
		mic_name = "R555"
		device_id = 0
    	#mic_name = "USB PnP Sound Device"
    #Sample rate is how often values are recorded
	sample_rate = 48000
    #Chunk is like a buffer, stores 2048 samples (bytes of data)
    #Advisable to use powers of 2 such as 1024 or 2048
	chunk_size = 2048

    #generate a list of all audio cards/microphones
	mic_list = sr.Microphone.list_microphone_names()
	print mic_list
	# for i, microphone_name in enumerate(mic_list):
	# 	if microphone_name == mic_name:
	# 		device_id = i

    #use the microphone as source for input. Here, we also specify
    #which device ID to specifically look for incase the microphone
    #is not working, an error will pop up saying "device_id undefined"
	with sr.Microphone(device_index = device_id, sample_rate = sample_rate, chunk_size = chunk_size) as source:
		recog.adjust_for_ambient_noise(source)
		recog.pause_threshold = 0.7
		while 1:
            #listens for the user's input
			audio = recog.listen(source)
			t_recog = threading.Thread(target = Recogize, name = person, args = (audio,))
			t_recog.start()

def Recogize(audio):
	person = current_thread().getName()
	try:
		index = queue_index.get()
		queue_index.put(index+1)
		text = recog.recognize_google(audio)
		# to prevent strange "u'somestring'" in print
		text = text.encode("utf8")
		queue_sentence.put({index: person + ": " + text})
	#error occurs when google could not understand what was said     
	except sr.UnknownValueError:
		print("Google Speech Recognition could not understand audio")    
	except sr.RequestError as e:
		print("Could not request results from Google Speech Recognition service; {0}".format(e))

# OutputSingle(): convert one dialoge sentence dictionary to string, and feed 
# into text classify function.
def OutputSingle():
	pick = queue_sentence.get()
	# add to whole dictionary
	log.update(pick)
	# send a string to text classification
	index = pick.keys()[0]
	output = str(index)+ " " + pick[index]
	classify_result = Vote(output)
	print output
	print classify_result
	# check for end of visit
	if "quit" in pick.values()[0]:
		p_doctor.terminate()
		p_patient.terminate()
		return 1
	return 0

# OutputWhole(log): sort the orderless dialoge dictionary, produce ordered 
# dialoge list
# @param[in] log: a dictionary containning all the sentences
def OutputWhole(log):
	temp = log
	whole = []
	for i in sorted(log.keys()):
		whole.append(temp[i])
	return whole

if __name__ == '__main__':
	log = {}
	recog = sr.Recognizer()
	queue_sentence = Manager().Queue()
	queue_index = Queue()
	queue_index.put(1)
	# pre-train the bayes network 
	# 
	# 
	#
	# 
	path = './dataset'
	files = sklearn.datasets.load_files(path, encoding = 'latin1', decode_error = 'replace', load_content=True, random_state=3)
	# print(files)
	count_vect = CountVectorizer()

	X_train_counts = count_vect.fit_transform(files.data)

	tfidf_transformer = TfidfTransformer()
	X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)
	# print(X_train_tfidf)
	# print("Target")
	# print(files)
	# print()
	# print((X_train_counts))
	svmi = svm.SVC(kernel = 'linear', probability=True)
	X = X_train_tfidf
	# pprint(files.values())
	Y = files["target"]
	print("Shapes")
	print(X.shape)
	print(Y.shape)
	h = svmi.fit(X, Y)
	print(h)
	# print("Now doing test files")
	#
	#
	#
	#
	p_doctor = Process(target = Record, args=("doctor",))
	p_patient = Process(target = Record, args=("patient",))
	p_patient.start()
	p_doctor.start()
	quit_flag = 0
	while(not quit_flag):
		quit_flag = OutputSingle()
	print OutputWhole(log)